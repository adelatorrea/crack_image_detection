{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2396ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import architectures as ar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43521774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Hyperparameters\n",
    "hyperparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 20,\n",
    "    \"ridge_lambda\": 0.01,\n",
    "    \"dropout_prob\": 0.5,\n",
    "    \"scheduler_step_size\": 7,\n",
    "    \"scheduler_gamma\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1609e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet18\n",
    "def get_resnet(num_classes = 1):\n",
    "  model = models.resnet18(pretrained=False) #Voy a entrenar todas las layers.\n",
    "\n",
    "  ### Ajuste de estructura ###\n",
    "  model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, num_classes),\n",
    "        ) \n",
    "\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e7f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_model = get_resnet(1).cuda()\n",
    "\n",
    "quality_model.load_state_dict(torch.load(r'architectures\\weights\\quality_model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38b3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahue\\AppData\\Local\\Temp\\ipykernel_10664\\1582622751.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r\"architectures\\weights\\quality_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada en la carpeta: ./output/bad_quality\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Verificar si hay una GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo y moverlo al dispositivo adecuado (GPU o CPU)\n",
    "model = get_resnet(1)\n",
    "model.load_state_dict(torch.load(r\"architectures\\weights\\quality_model.pth\"))\n",
    "model.to(device)  # Mover el modelo al dispositivo adecuado\n",
    "model.eval()\n",
    "\n",
    "# Transformación de la imagen\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar la imagen a las dimensiones de entrada de ResNet\n",
    "    transforms.ToTensor(),  # Convertir la imagen a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalización\n",
    "])\n",
    "\n",
    "# Cargar la imagen desde el archivo local\n",
    "image_name = os.listdir(\"input\")[0]\n",
    "image_path = f'input/{image_name}'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = transform(image).unsqueeze(0).to(device)  # Mover la imagen al dispositivo\n",
    "\n",
    "# Realizar la predicción\n",
    "with torch.no_grad():  # No calcular gradientes para la predicción\n",
    "    output = model(image)  # Realizar la predicción\n",
    "    output_s = torch.sigmoid(output)\n",
    "    predicted_class = (output_s > 0.5).float().cpu().numpy()  # Convertir a clase (0 o 1 para clasificación binaria)\n",
    "\n",
    "if predicted_class[-1][-1] == 1:\n",
    "    folder = \"bad_quality\"\n",
    "else:\n",
    "    folder = \"good_quality\"\n",
    "    \n",
    "# Crear las carpetas si no existen\n",
    "class_folder = f'./output/{folder}'\n",
    "os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "# Copiar la imagen a la carpeta correspondiente\n",
    "shutil.copy(image_path, class_folder)\n",
    "\n",
    "print(f\"Imagen guardada en la carpeta: {class_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554e0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import architectures.zero_dce_model as zero\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbae5797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zero_dce(\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (e_conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv5): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (e_conv7): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero.zero_dce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d46b2204-5b38-4c62-8c80-10a3f2b3d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowlight(image):\n",
    "    \n",
    "    if len(os.listdir(r\"C:\\Users\\nahue\\Desktop\\proyectos\\TFM\\notebooks\\output\\bad_quality\")) == 0:\n",
    "        return None\n",
    "        \n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "    data_lowlight = Image.open(image_path)\n",
    "    \n",
    "    data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "    \n",
    "    \n",
    "    data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "    data_lowlight = data_lowlight.permute(2,0,1)\n",
    "    data_lowlight = data_lowlight.cuda().unsqueeze(0)\n",
    "    \n",
    "    DCE_net = zero.zero_dce().cuda()\n",
    "    DCE_net.load_state_dict(torch.load('architectures/weights/zero_dce.pth')) #Weights\n",
    "    #start = time.time()\n",
    "    _,enhanced_image,_ = DCE_net(data_lowlight)\n",
    "    \n",
    "    #end_time = (time.time() - start)\n",
    "    #print(end_time)\n",
    "    image_path = image_path.replace('bad_quality','good_quality')\n",
    "    result_path = image_path\n",
    "    if not os.path.exists(image_path.replace('/'+image_path.split(\"/\")[-1],'')):\n",
    "        os.makedirs(image_path.replace('/'+image_path.split(\"/\")[-1],''))\n",
    "    \n",
    "    torchvision.utils.save_image(enhanced_image, result_path)\n",
    "    \n",
    "    return result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe4a468-91fa-48ef-9be1-78385108d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahue\\AppData\\Local\\Temp\\ipykernel_21172\\859185741.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  DCE_net.load_state_dict(torch.load('architectures/weights/zero_dce.pth')) #Weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nahue\\\\Desktop\\\\proyectos\\\\TFM\\\\notebooks\\\\output\\\\good_quality\\\\classified_image.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowlight(r\"C:\\Users\\nahue\\Desktop\\proyectos\\TFM\\notebooks\\output\\bad_quality\\classified_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40869cf1-465e-4838-8408-9626eff6c07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\gradio\\blocks.py\", line 2019, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\gradio\\blocks.py\", line 1566, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2364, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 864, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\gradio\\utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\nahue\\AppData\\Local\\Temp\\ipykernel_21172\\859185741.py\", line 7, in lowlight\n",
      "    data_lowlight = Image.open(image_path)\n",
      "  File \"C:\\Users\\nahue\\anaconda3\\envs\\py3-10\\lib\\site-packages\\PIL\\Image.py\", line 3256, in open\n",
      "    prefix = fp.read(16)\n",
      "AttributeError: 'Image' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# Crear la interfaz Gradio\n",
    "iface = gr.Interface(\n",
    "    fn=lowlight,\n",
    "    inputs=gr.Image(type=\"pil\"),  # El input es una imagen en formato PIL\n",
    "    outputs=[gr.Image()], \n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc141a-458a-4fa0-8583-56e1f65fef5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
